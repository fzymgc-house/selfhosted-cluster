# Self-Hosted Kubernetes Cluster

A comprehensive Kubernetes cluster setup for home infrastructure using k3s and Terraform. This repository provides Infrastructure as Code (IaC) for a complete self-hosted platform including identity management, monitoring, databases, and application deployment.

## ğŸ—ï¸ Architecture Overview

This repository implements a production-ready home cluster with the following architecture:

- **Hardware**: TuringPi 2 cluster boards with RK1 and Jetson Orin NX compute modules
- **OS**: Armbian 25.08 (Ubuntu Noble) with systemd-networkd
- **Kubernetes**: k3s lightweight distribution
- **Infrastructure**: Terraform for external service configuration
- **Networking**: Calico CNI with MetalLB load balancing
- **Storage**: Longhorn distributed storage
- **Ingress**: Traefik with automatic TLS via cert-manager
- **Security**: HashiCorp Vault for secrets management
- **Identity**: Authentik SSO with OIDC integration
- **Monitoring**: VictoriaMetrics + Grafana stack

## ğŸ“ Repository Structure

```
selfhosted-cluster/
â”œâ”€â”€ ansible/                    # Cluster deployment and node management
â”‚   â”œâ”€â”€ inventory/              # Host definitions and group variables
â”‚   â”œâ”€â”€ roles/                  # Ansible roles for automation
â”‚   â”‚   â”œâ”€â”€ k3sup/              # k3s cluster deployment
â”‚   â”‚   â””â”€â”€ tp2-bootstrap-node/ # Node preparation and configuration
â”‚   â”œâ”€â”€ k3s-playbook.yml        # Main cluster deployment playbook
â”‚   â”œâ”€â”€ bootstrap-nodes-playbook.yml # Node preparation playbook
â”‚   â””â”€â”€ reboot-nodes-playbook.yml     # Cluster maintenance playbook
â”œâ”€â”€ argocd/                     # Kubernetes manifests and ArgoCD configurations
â”‚   â”œâ”€â”€ app-configs/            # Application-specific configurations
â”‚   â””â”€â”€ cluster-app/            # Cluster-wide application set
â”œâ”€â”€ tf/                         # Terraform modules for external services
â”‚   â”œâ”€â”€ vault/                  # Vault configuration and policies
â”‚   â”œâ”€â”€ authentik/              # Identity provider setup
â”‚   â”œâ”€â”€ grafana/                # Grafana dashboards and data sources
â”‚   â””â”€â”€ core-services/          # Additional service configurations
```

## ğŸ–¥ï¸ Hardware Configuration

### TuringPi Cluster Setup
- **1x TuringPi 2** cluster board (2x TPI hosts: alpha/beta)
- **4x RK1** compute modules (ARM64, 32GB RAM each)
- **4x Jetson Orin NX** compute modules (ARM64, AI/ML workloads)

### Network Architecture
- **Cluster Network**: `10.42.0.0/16` (pod CIDR)
- **Service Network**: `10.43.0.0/16` (service CIDR)
- **K8s API VIP**: `192.168.20.140` (kube-vip on control plane nodes)
- **MetalLB Pools**: `192.168.20.145-149`, `192.168.20.155-159` (LoadBalancer IPs)
- **DNS**: Internal cluster DNS at `10.43.0.10`

## ğŸš€ Quick Start

### Prerequisites

1. **Local Development Machine**:
   - Ansible with kubernetes.core collection
   - kubectl configured
   - 1Password CLI (for secrets management)

2. **Hardware Setup**:
   - TuringPi 2 with compute modules installed
   - Network connectivity to all nodes
   - BMC access configured

### Deployment Steps

#### 1. Prepare Nodes
```bash
# Bootstrap all cluster nodes with base configuration
ansible-playbook -i ansible/inventory/hosts.yml ansible/bootstrap-nodes-playbook.yml
```

#### 2. Deploy Kubernetes Cluster
```bash
# Deploy k3s cluster with all infrastructure components
ansible-playbook -i ansible/inventory/hosts.yml ansible/k3s-playbook.yml
```

#### 3. Verify Deployment
```bash
# Check cluster status
kubectl --context fzymgc-house get nodes
kubectl --context fzymgc-house get pods -A
```

## ğŸ“¦ Deployed Applications

### Core Infrastructure
- **ğŸŒ Traefik**: Ingress controller with automatic TLS
- **ğŸ”’ cert-manager**: TLS certificate automation
- **âš–ï¸ MetalLB**: Bare-metal load balancer
- **ğŸ’¾ Longhorn**: Distributed block storage
- **ğŸ›¡ï¸ Calico**: Container networking (CNI)

### Platform Services
- **ğŸ” HashiCorp Vault**: Secrets and certificate management
- **ğŸ‘¤ Authentik**: Identity provider with SSO/OIDC
- **ğŸ—„ï¸ CloudNativePG**: PostgreSQL database clusters
- **âš¡ Valkey**: Redis-compatible in-memory database
- **ğŸ“Š VictoriaMetrics**: Metrics collection and storage
- **ğŸ“ˆ Grafana**: Observability and dashboards

### Infrastructure as Code
- **ğŸ—ï¸ Terraform**: External service configuration
- **ğŸ“ SOPS**: Encrypted secrets in Git
- **ğŸ¯ Kustomize**: Kubernetes manifest management

## ğŸ”§ Configuration Management

### Ansible Automation
The `ansible/` directory contains all automation for cluster lifecycle:

- **Node Bootstrap**: OS configuration, networking, security hardening
- **Cluster Deployment**: k3s installation with k3sup
- **Infrastructure Setup**: Core services installation
- **Maintenance Operations**: Updates, reboots, scaling

### Application Management
The repository contains Kubernetes manifests for application deployment:

- **Infrastructure Controllers**: Core Kubernetes controllers
- **Infrastructure Configs**: Cluster-wide configurations and policies
- **Applications**: User-facing services and dashboards

### Terraform Integration
The `tf/` directory provides Infrastructure as Code for external services:

- **Vault Management**: Policies, auth methods, PKI
- **Authentik Configuration**: OIDC applications, user groups
- **Grafana Configuration**: Dashboards, data sources, folders
- **External Integrations**: Cloud services, DNS, monitoring

## ğŸ›¡ï¸ Security Features

### Zero-Trust Architecture
- **mTLS Everywhere**: Service mesh communication
- **RBAC**: Kubernetes role-based access control
- **Network Policies**: Micro-segmentation
- **Pod Security Standards**: Container security enforcement

### Secrets Management
- **HashiCorp Vault**: Centralized secrets storage
- **External Secrets Operator**: Kubernetes secrets injection
- **SOPS Encryption**: Git-stored encrypted secrets
- **Automatic Rotation**: Certificate and credential lifecycle

### Identity & Access
- **Authentik SSO**: Single sign-on for all services
- **OIDC Integration**: Standards-based authentication
- **MFA Support**: Multi-factor authentication
- **Fine-grained RBAC**: Service-level permissions

## ğŸ“Š Monitoring & Observability

### Metrics & Alerting
- **VictoriaMetrics**: High-performance metrics storage
- **Grafana**: Rich dashboards and visualization
- **Built-in Dashboards**: Cluster, application, and business metrics
- **Alert Manager**: Intelligent alert routing

### Logging & Tracing
- **Structured Logging**: JSON-formatted application logs
- **Centralized Collection**: Cluster-wide log aggregation
- **Retention Policies**: Automated log lifecycle management

## ğŸ”„ Application Deployment

### Manual Deployment
1. **Source Control**: All infrastructure defined in Git
2. **Manual Application**: Kubernetes resources applied manually or via CI/CD
3. **Declarative Updates**: Kubernetes resources managed through manifests
4. **Version Control**: Git-based change history

### Development Process
1. Make changes to manifests in feature branches
2. Create pull request for review
3. Merge to main branch
4. Apply changes to cluster manually or via automation

## ğŸ  Domain & Services

### External Access
All services are accessible via `*.fzymgc.house` domains:

- **Grafana**: https://grafana.fzymgc.house
- **Authentik**: https://auth.fzymgc.house
- **Vault**: https://vault.fzymgc.house
- **Traefik Dashboard**: https://traefik.fzymgc.house

### SSL/TLS
- **Automatic Certificates**: cert-manager with Let's Encrypt
- **Internal CA**: Custom certificate authority for internal services
- **Wildcard Certificates**: Efficient certificate management

## ğŸ”§ Maintenance Operations

### Cluster Updates
```bash
# Update all nodes
ansible-playbook -i ansible/inventory/hosts.yml ansible/reboot-nodes-playbook.yml

# Update specific components
ansible-playbook -i ansible/inventory/hosts.yml ansible/k3s-playbook.yml --tags k8s-longhorn
```

### Application Management
```bash
# Apply application changes
kubectl apply -k path/to/application

# Check application status
kubectl get all -n application-namespace

# View application logs
kubectl logs -n application-namespace -l app=application-name
```

### Backup & Recovery
- **Automated Backups**: Longhorn volume snapshots
- **Database Backups**: PostgreSQL streaming backup to object storage
- **Vault Snapshots**: Automated Vault data backup
- **Disaster Recovery**: Full cluster restore procedures

## ğŸ“š Additional Resources

### Documentation
- [Traefik Ingress](https://doc.traefik.io/traefik/)
- [Longhorn Storage](https://longhorn.io/docs/)
- [HashiCorp Vault](https://developer.hashicorp.com/vault)

### Troubleshooting
- Check application status: `kubectl get all -A`
- View logs: `kubectl logs -n namespace -l app=app-name`
- Validate manifests: `kubectl apply --dry-run=client -k path/to/manifests`

## ğŸ“„ License

This project is licensed under the MIT License - see the individual files for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly in a development environment
5. Submit a pull request with detailed description

---

**Note**: This is a personal home infrastructure setup. Adapt configurations for your specific environment and security requirements.
