# Self-Hosted Kubernetes Cluster

A comprehensive Kubernetes cluster setup for home infrastructure using k3s and Terraform. This repository provides Infrastructure as Code (IaC) for a complete self-hosted platform including identity management, monitoring, databases, and application deployment.

## 🏗️ Architecture Overview

This repository implements a production-ready home cluster with the following architecture:

- **Hardware**: TuringPi 2 cluster boards with RK1 and Jetson Orin NX compute modules
- **OS**: Armbian 25.08 (Ubuntu Noble) with systemd-networkd
- **Kubernetes**: k3s lightweight distribution
- **Infrastructure**: Terraform for external service configuration
- **Networking**: Calico CNI with MetalLB load balancing
- **Storage**: Longhorn distributed storage
- **Ingress**: Traefik with automatic TLS via cert-manager
- **Security**: HashiCorp Vault for secrets management
- **Identity**: Authentik SSO with OIDC integration
- **Monitoring**: VictoriaMetrics + Grafana stack

## 📁 Repository Structure

```
selfhosted-cluster/
├── ansible/                    # Cluster deployment and node management
│   ├── inventory/              # Host definitions and group variables
│   ├── roles/                  # Ansible roles for automation
│   │   ├── k3sup/              # k3s cluster deployment
│   │   └── tp2-bootstrap-node/ # Node preparation and configuration
│   ├── k3s-playbook.yml        # Main cluster deployment playbook
│   ├── bootstrap-nodes-playbook.yml # Node preparation playbook
│   └── reboot-nodes-playbook.yml     # Cluster maintenance playbook
├── tf/                         # Terraform modules for external services
│   ├── vault/                  # Vault configuration and policies
│   ├── authentik/              # Identity provider setup
│   └── core-services/          # Additional service configurations
└── containers/                 # Custom container images
```

## 🖥️ Hardware Configuration

### TuringPi Cluster Setup
- **1x TuringPi 2** cluster board (2x TPI hosts: alpha/beta)
- **4x RK1** compute modules (ARM64, 32GB RAM each)
- **4x Jetson Orin NX** compute modules (ARM64, AI/ML workloads)

### Network Architecture
- **Cluster Network**: `10.42.0.0/16` (pod CIDR)
- **Service Network**: `10.43.0.0/16` (service CIDR)
- **Load Balancer**: `10.255.254.6` (MetalLB pool)
- **DNS**: Internal cluster DNS at `10.43.0.10`

## 🚀 Quick Start

### Prerequisites

1. **Local Development Machine**:
   - Ansible with kubernetes.core collection
   - kubectl configured
   - 1Password CLI (for secrets management)

2. **Hardware Setup**:
   - TuringPi 2 with compute modules installed
   - Network connectivity to all nodes
   - BMC access configured

### Deployment Steps

#### 1. Prepare Nodes
```bash
# Bootstrap all cluster nodes with base configuration
ansible-playbook -i ansible/inventory/hosts.yml ansible/bootstrap-nodes-playbook.yml
```

#### 2. Deploy Kubernetes Cluster
```bash
# Deploy k3s cluster with all infrastructure components
ansible-playbook -i ansible/inventory/hosts.yml ansible/k3s-playbook.yml
```

#### 3. Verify Deployment
```bash
# Check cluster status
kubectl --context fzymgc-house get nodes
kubectl --context fzymgc-house get pods -A
```

## 📦 Deployed Applications

### Core Infrastructure
- **🌐 Traefik**: Ingress controller with automatic TLS
- **🔒 cert-manager**: TLS certificate automation
- **⚖️ MetalLB**: Bare-metal load balancer
- **💾 Longhorn**: Distributed block storage
- **🛡️ Calico**: Container networking (CNI)

### Platform Services
- **🔐 HashiCorp Vault**: Secrets and certificate management
- **👤 Authentik**: Identity provider with SSO/OIDC
- **🗄️ CloudNativePG**: PostgreSQL database clusters
- **⚡ Valkey**: Redis-compatible in-memory database
- **📊 VictoriaMetrics**: Metrics collection and storage
- **📈 Grafana**: Observability and dashboards

### Infrastructure as Code
- **🏗️ Terraform**: External service configuration
- **📝 SOPS**: Encrypted secrets in Git
- **🎯 Kustomize**: Kubernetes manifest management

## 🔧 Configuration Management

### Ansible Automation
The `ansible/` directory contains all automation for cluster lifecycle:

- **Node Bootstrap**: OS configuration, networking, security hardening
- **Cluster Deployment**: k3s installation with k3sup
- **Infrastructure Setup**: Core services installation
- **Maintenance Operations**: Updates, reboots, scaling

### Application Management
The repository contains Kubernetes manifests for application deployment:

- **Infrastructure Controllers**: Core Kubernetes controllers
- **Infrastructure Configs**: Cluster-wide configurations and policies  
- **Applications**: User-facing services and dashboards

### Terraform Integration
The `tf/` directory provides Infrastructure as Code for external services:

- **Vault Management**: Policies, auth methods, PKI
- **Authentik Configuration**: OIDC applications, user groups
- **External Integrations**: Cloud services, DNS, monitoring

## 🛡️ Security Features

### Zero-Trust Architecture
- **mTLS Everywhere**: Service mesh communication
- **RBAC**: Kubernetes role-based access control
- **Network Policies**: Micro-segmentation
- **Pod Security Standards**: Container security enforcement

### Secrets Management
- **HashiCorp Vault**: Centralized secrets storage
- **External Secrets Operator**: Kubernetes secrets injection
- **SOPS Encryption**: Git-stored encrypted secrets
- **Automatic Rotation**: Certificate and credential lifecycle

### Identity & Access
- **Authentik SSO**: Single sign-on for all services
- **OIDC Integration**: Standards-based authentication
- **MFA Support**: Multi-factor authentication
- **Fine-grained RBAC**: Service-level permissions

## 📊 Monitoring & Observability

### Metrics & Alerting
- **VictoriaMetrics**: High-performance metrics storage
- **Grafana**: Rich dashboards and visualization
- **Built-in Dashboards**: Cluster, application, and business metrics
- **Alert Manager**: Intelligent alert routing

### Logging & Tracing
- **Structured Logging**: JSON-formatted application logs
- **Centralized Collection**: Cluster-wide log aggregation
- **Retention Policies**: Automated log lifecycle management

## 🔄 Application Deployment

### Manual Deployment
1. **Source Control**: All infrastructure defined in Git
2. **Manual Application**: Kubernetes resources applied manually or via CI/CD
3. **Declarative Updates**: Kubernetes resources managed through manifests
4. **Version Control**: Git-based change history

### Development Process
1. Make changes to manifests in feature branches
2. Create pull request for review
3. Merge to main branch
4. Apply changes to cluster manually or via automation

## 🏠 Domain & Services

### External Access
All services are accessible via `*.fzymgc.house` domains:

- **Grafana**: https://grafana.fzymgc.house
- **Authentik**: https://auth.fzymgc.house  
- **Vault**: https://vault.fzymgc.house
- **Traefik Dashboard**: https://traefik.fzymgc.house

### SSL/TLS
- **Automatic Certificates**: cert-manager with Let's Encrypt
- **Internal CA**: Custom certificate authority for internal services
- **Wildcard Certificates**: Efficient certificate management

## 🔧 Maintenance Operations

### Cluster Updates
```bash
# Update all nodes
ansible-playbook -i ansible/inventory/hosts.yml ansible/reboot-nodes-playbook.yml

# Update specific components
ansible-playbook -i ansible/inventory/hosts.yml ansible/k3s-playbook.yml --tags k8s-longhorn
```

### Application Management
```bash
# Apply application changes
kubectl apply -k path/to/application

# Check application status
kubectl get all -n application-namespace

# View application logs
kubectl logs -n application-namespace -l app=application-name
```

### Backup & Recovery
- **Automated Backups**: Longhorn volume snapshots
- **Database Backups**: PostgreSQL streaming backup to object storage
- **Vault Snapshots**: Automated Vault data backup
- **Disaster Recovery**: Full cluster restore procedures

## 📚 Additional Resources

### Documentation
- [Traefik Ingress](https://doc.traefik.io/traefik/)
- [Longhorn Storage](https://longhorn.io/docs/)
- [HashiCorp Vault](https://developer.hashicorp.com/vault)

### Troubleshooting
- Check application status: `kubectl get all -A`
- View logs: `kubectl logs -n namespace -l app=app-name`
- Validate manifests: `kubectl apply --dry-run=client -k path/to/manifests`

## 📄 License

This project is licensed under the MIT License - see the individual files for details.

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly in a development environment
5. Submit a pull request with detailed description

---

**Note**: This is a personal home infrastructure setup. Adapt configurations for your specific environment and security requirements.

