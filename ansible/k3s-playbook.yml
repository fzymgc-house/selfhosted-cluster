# SPDX-License-Identifier: MIT-0
# code: language=ansible
---
# k3s Cluster Deployment Playbook
#
# This playbook deploys a k3s cluster using native Ansible roles.
# Execution order:
#   1. First control plane node initializes cluster
#   2. Additional control plane nodes join
#   3. kube-vip deployed for API endpoint HA
#   4. Worker nodes join
#   5. Calico CNI is installed
#   6. CSI snapshot controller is installed
#   7. Additional Longhorn disks are configured (if defined in host_vars)
#   8. Longhorn disk configuration is registered with cluster

# Phase 1: First control plane node
- name: Initialize k3s cluster on first control plane node
  hosts: tp_cluster_controlplane[0]
  become: true
  roles:
    - role: k3s-storage
      tags:
        - k3s-storage
    - role: k3s-server
      vars:
        k3s_is_first_server: true
      tags:
        - k3s-server
        - k3s-install
  tasks:
    - name: Fetch join token from first server
      ansible.builtin.slurp:
        src: /var/lib/rancher/k3s/server/node-token
      register: k3s_token_raw
      tags:
        - k3s-token

    - name: Propagate join token to all cluster nodes
      ansible.builtin.set_fact:
        k3s_join_token: "{{ k3s_token_raw.content | b64decode | trim }}"
      delegate_to: "{{ item }}"
      delegate_facts: true
      loop: "{{ groups['tp_cluster_nodes'] }}"
      tags:
        - k3s-token

    - name: Propagate cluster k3s version to all nodes
      ansible.builtin.set_fact:
        k3s_cluster_version: "{{ k3s_installed_version }}"
      delegate_to: "{{ item }}"
      delegate_facts: true
      loop: "{{ groups['tp_cluster_nodes'] }}"
      when: k3s_installed_version is defined and k3s_installed_version != ""
      tags:
        - k3s-version

    - name: Check if local kubeconfig exists
      ansible.builtin.stat:
        path: "{{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml"
      register: local_kubeconfig
      delegate_to: localhost
      become: false
      tags:
        - k3s-kubeconfig

    - name: Validate existing kubeconfig
      ansible.builtin.command:
        cmd: kubectl --kubeconfig {{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml cluster-info
      delegate_to: localhost
      become: false
      register: kubeconfig_valid
      failed_when: false
      changed_when: false
      when: local_kubeconfig.stat.exists
      tags:
        - k3s-kubeconfig

    - name: Copy kubeconfig to local machine
      ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: "{{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml"
        flat: true
      when: not local_kubeconfig.stat.exists or (kubeconfig_valid.rc | default(0)) != 0
      register: kubeconfig_fetched
      tags:
        - k3s-kubeconfig

    - name: Update kubeconfig server URL
      ansible.builtin.replace:
        path: "{{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml"
        regexp: "server: https://127.0.0.1:6443"
        replace: "server: https://{{ k8s_cluster_endpoint_name }}:6443"
      delegate_to: localhost
      become: false
      when: kubeconfig_fetched.changed | default(false)
      tags:
        - k3s-kubeconfig

    - name: Update kubeconfig context name
      ansible.builtin.replace:
        path: "{{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml"
        regexp: "name: default"
        replace: "name: {{ k8s_context }}"
      delegate_to: localhost
      become: false
      when: kubeconfig_fetched.changed | default(false)
      tags:
        - k3s-kubeconfig

# Phase 2: Additional control plane nodes
- name: Join additional control plane nodes
  hosts: tp_cluster_controlplane[1:]
  become: true
  serial: 1
  roles:
    - role: k3s-storage
      tags:
        - k3s-storage
    - role: k3s-server
      vars:
        k3s_is_first_server: false
      tags:
        - k3s-server
        - k3s-install

# Phase 3: Deploy kube-vip for API HA
- name: Deploy kube-vip on control plane nodes
  hosts: tp_cluster_controlplane
  become: true
  roles:
    - role: kube-vip
      tags:
        - kube-vip

# Phase 4: Worker nodes
- name: Join worker nodes
  hosts: tp_cluster_workers
  become: true
  roles:
    - role: k3s-storage
      tags:
        - k3s-storage
    - role: k3s-agent
      tags:
        - k3s-agent
        - k3s-install

# Phase 5: Install Calico CNI
- name: Install Calico CNI
  hosts: tp_cluster_controlplane[0]
  gather_facts: false
  roles:
    - role: calico
      tags:
        - k3s-calico
        - calico

# Phase 6: CSI Snapshot Controller
- name: Install CSI snapshot controller
  hosts: tp_cluster_controlplane[0]
  gather_facts: false
  tasks:
    - name: Apply CSI snapshot controller
      ansible.builtin.shell:
        cmd: |
          kubectl --kubeconfig {{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml \
            apply -k {{ playbook_dir }}/files/csi-snapshot-setup
      delegate_to: localhost
      become: false
      register: csi_snapshot_result
      changed_when: "'created' in csi_snapshot_result.stdout or 'configured' in csi_snapshot_result.stdout"
      tags:
        - k3s-csi-snapshot-controller

# Phase 7: Configure additional Longhorn disks
- name: Configure additional Longhorn storage disks
  hosts: tp_cluster_nodes
  become: true
  roles:
    - role: longhorn-disks
      tags:
        - longhorn-disks

# Phase 8: Register Longhorn disk configuration
- name: Register Longhorn disk configuration
  hosts: tp_cluster_nodes
  gather_facts: false
  vars:
    longhorn_kubeconfig: "{{ lookup('env', 'HOME') }}/.kube/configs/{{ k8s_context }}-admin.yml"
  tasks:
    - name: Validate k8s_context is defined
      ansible.builtin.assert:
        that:
          - k8s_context is defined
          - k8s_context | length > 0
        fail_msg: |
          k8s_context variable is not defined or is empty.
          This variable is required to locate the kubeconfig file.
          Set it in inventory or pass via -e k8s_context=your-context
        quiet: true
      run_once: true
      tags:
        - longhorn-disks
        - longhorn-register

    - name: Verify kubeconfig exists
      ansible.builtin.stat:
        path: "{{ longhorn_kubeconfig }}"
      register: kubeconfig_stat
      delegate_to: localhost
      become: false
      run_once: true
      tags:
        - longhorn-disks
        - longhorn-register

    - name: Fail if kubeconfig not found
      ansible.builtin.fail:
        msg: |
          Kubeconfig not found at {{ longhorn_kubeconfig }}
          Ensure k8s_context is set correctly and kubeconfig file exists.
          Current k8s_context: {{ k8s_context | default('undefined') }}
      when: not kubeconfig_stat.stat.exists
      run_once: true
      tags:
        - longhorn-disks
        - longhorn-register

    # Note: longhorn_kubeconfig is inherited from play-level vars above
    - name: Register disks with Longhorn
      ansible.builtin.include_role:
        name: longhorn-disks
        tasks_from: register-with-longhorn.yml
      when: longhorn_additional_disks is defined and longhorn_additional_disks | length > 0
      tags:
        - longhorn-disks
        - longhorn-register
