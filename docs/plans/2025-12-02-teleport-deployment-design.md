# Teleport Deployment Design

## Overview

Deploy Goteleport as a self-hosted zero-trust access platform providing:

- **SSH access** to cluster nodes with audit logging and session recording
- **Kubernetes access** replacing direct kubectl authentication with Teleport's RBAC

Database access will be added in a future phase.

## Architecture

### Core Services (Kubernetes)

**Teleport Auth Service** - Single replica Deployment handling authentication, authorization, and certificate signing. Connects to PostgreSQL for state and Vault for secret material.

**Teleport Proxy Service** - Single replica Deployment serving the web UI at `teleport.fzymgc.house` and proxying all client connections.

### Node Agents (Ansible-deployed)

**Teleport SSH Service** - Systemd service on each cluster node (tpi-alpha-1 through tpi-alpha-4), providing audited SSH access.

### Supporting Infrastructure

| Component | Purpose |
|-----------|---------|
| PostgreSQL | Dedicated CNPG cluster for Teleport backend state |
| Vault | Stores CA keys, join tokens, OIDC credentials |
| Authentik | OIDC provider for user authentication |
| cert-manager | TLS certificate for `teleport.fzymgc.house` |

### Authentication Flow

Users authenticate via Authentik → receive Teleport certificates → access nodes and Kubernetes with short-lived credentials and full audit logging.

## Kubernetes Resources

**Namespace:** `teleport`

### PostgreSQL (CNPG)

- Cluster: `teleport-db`, single instance, 5Gi storage
- Database: `teleport`, User: `teleport`
- Credentials stored at `secret/fzymgc-house/cluster/teleport/db`

### Deployments

| Name | Purpose |
|------|---------|
| `teleport-auth` | Auth service with Postgres and Vault integration |
| `teleport-proxy` | Proxy service, web UI, connection routing |

### Services

| Name | Type | Ports |
|------|------|-------|
| `teleport-auth` | ClusterIP | 3025, 3026 |
| `teleport-proxy` | LoadBalancer | 443, 3023, 3024, 3026 |

### Secrets (via ExternalSecrets)

| Secret | Vault Path |
|--------|------------|
| `teleport-db-credentials` | `secret/fzymgc-house/cluster/teleport/db` |
| `teleport-ca` | `secret/fzymgc-house/cluster/teleport/ca` |
| `teleport-join-token` | `secret/fzymgc-house/cluster/teleport/join-token` |
| `teleport-oidc` | `secret/fzymgc-house/cluster/teleport/oidc` |

### Ingress

- IngressRoute: `teleport.fzymgc.house` → teleport-proxy:443
- TLS via cert-manager (Let's Encrypt)
- SSH (3023) and tunnel (3024) ports bypass Traefik via LoadBalancer

## Authentik Integration

### Terraform Resources

**OIDC Provider:**
- Name: `teleport`
- Client ID: `teleport`
- Client Secret: stored at `secret/fzymgc-house/cluster/teleport/oidc`
- Redirect URI: `https://teleport.fzymgc.house/v1/webapi/oidc/callback`
- Scopes: `openid`, `profile`, `email`, `groups`

**Application:**
- Name: `Teleport`
- Linked to OIDC provider

**Groups:**
- `teleport-admins` - Full admin access
- `teleport-users` - Standard SSH and kubectl access

### Teleport Role Mapping

| Authentik Group | Teleport Role |
|-----------------|---------------|
| `teleport-admins` | `admin` |
| `teleport-users` | `access` |

## Vault Configuration

### Secret Paths

| Path | Contents |
|------|----------|
| `secret/fzymgc-house/cluster/teleport/db` | Postgres credentials |
| `secret/fzymgc-house/cluster/teleport/ca` | CA private key and certificate |
| `secret/fzymgc-house/cluster/teleport/join-token` | Node registration token |
| `secret/fzymgc-house/cluster/teleport/oidc` | Authentik client secret |

### Policy

**Name:** `teleport`

```hcl
path "secret/data/fzymgc-house/cluster/teleport/*" {
  capabilities = ["read"]
}
```

### Kubernetes Auth Role

- Role: `teleport`
- Bound service account: `teleport` in namespace `teleport`
- Policies: `teleport`

### Initial Secret Population

- **CA key/cert:** Generated by Teleport on first boot, then extracted and stored in Vault
- **Join token:** Generated randomly, stored in Vault
- **OIDC client secret:** Created when Authentik provider is provisioned

## Ansible Node Agent Deployment

### New Role: `teleport-agent`

**Tasks:**
1. Add Teleport APT repository (ARM64 packages)
2. Install `teleport` package
3. Deploy `/etc/teleport.yaml` configuration
4. Deploy join token (fetched from Vault)
5. Enable and start `teleport` systemd service
6. Verify agent registration

### Node Configuration

```yaml
teleport:
  nodename: "{{ inventory_hostname }}"
  auth_token: "{{ teleport_join_token }}"
  auth_server: "teleport.fzymgc.house:443"
  log:
    severity: INFO

ssh_service:
  enabled: true
  labels:
    env: production
    role: "{{ 'control-plane' if 'control_plane' in group_names else 'worker' }}"
```

### Playbook

`ansible/teleport-agents-playbook.yml` targeting `tp_cluster_nodes` group.

## Kubernetes Access

### Configuration

The `kubernetes_service` runs alongside auth/proxy, registering the cluster as `fzymgc-house`.

### RBAC

- ServiceAccount: `teleport` in namespace `teleport`
- ClusterRole: `teleport-kubernetes-access` with impersonation permissions
- ClusterRoleBinding: binds role to service account

### Role Mapping

| Authentik Group | Kubernetes Access |
|-----------------|-------------------|
| `teleport-admins` | cluster-admin equivalent |
| `teleport-users` | Namespace-scoped (configurable) |

### User Experience

```bash
tsh login --proxy=teleport.fzymgc.house
tsh kube login fzymgc-house
kubectl get pods  # Authenticated via Teleport
```

## Implementation Phases

### Phase 1: Core Infrastructure

- Create `teleport` namespace and CNPG PostgreSQL cluster
- Configure Vault policy and secrets paths
- Create ExternalSecrets for database credentials

### Phase 2: Teleport Auth & Proxy

- Deploy Teleport auth service with Postgres backend
- Deploy Teleport proxy service
- Configure IngressRoute and LoadBalancer
- Generate and store CA material in Vault

### Phase 3: Authentik Integration

- Create Terraform resources for OIDC provider and application
- Create `teleport-admins` and `teleport-users` groups
- Configure Teleport OIDC connector
- Test web login flow

### Phase 4: Kubernetes Access

- Configure `kubernetes_service` in Teleport
- Create RBAC resources for impersonation
- Test `tsh kube login` and kubectl access

### Phase 5: Node SSH Access

- Create Ansible role `teleport-agent`
- Store join token in Vault
- Deploy agents to all 4 nodes
- Test `tsh ssh` access with session recording

## Future Enhancements

- Database access (PostgreSQL via CNPG)
- Additional node groups (Jetson, future hardware)
- Session recording storage (S3-compatible)
